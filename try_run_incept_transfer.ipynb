{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from train_inception import feature_extraction_InV3, train_last_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.layers import Dense,GlobalAveragePooling2D,BatchNormalization\n",
    "from keras import applications\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width=299\n",
    "img_height = 299\n",
    "train_data_dir = \"data/train\"\n",
    "num_image=1439\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1439 images belonging to 4 classes.\n",
      "96/96 [==============================] - 660s 7s/step\n",
      "(1439, 2048) (1439, 4)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_y=feature_extraction_InV3(img_width, img_height,\n",
    "                        train_data_dir,\n",
    "                        num_image,\n",
    "                        epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1295 samples, validate on 144 samples\n",
      "Epoch 1/100\n",
      "1295/1295 [==============================] - 7s 5ms/step - loss: 0.8915 - acc: 0.6409 - val_loss: 1.5084 - val_acc: 0.2917\n",
      "Epoch 2/100\n",
      "1295/1295 [==============================] - 1s 432us/step - loss: 0.4599 - acc: 0.8440 - val_loss: 1.4535 - val_acc: 0.3542\n",
      "Epoch 3/100\n",
      "1295/1295 [==============================] - 1s 480us/step - loss: 0.3447 - acc: 0.8842 - val_loss: 1.2750 - val_acc: 0.4444\n",
      "Epoch 4/100\n",
      "1295/1295 [==============================] - 1s 428us/step - loss: 0.2741 - acc: 0.9189 - val_loss: 1.0074 - val_acc: 0.5347\n",
      "Epoch 5/100\n",
      "1295/1295 [==============================] - 1s 470us/step - loss: 0.2148 - acc: 0.9382 - val_loss: 0.9026 - val_acc: 0.5764\n",
      "Epoch 6/100\n",
      "1295/1295 [==============================] - 1s 517us/step - loss: 0.1978 - acc: 0.9444 - val_loss: 1.0213 - val_acc: 0.5486\n",
      "Epoch 7/100\n",
      "1295/1295 [==============================] - 1s 437us/step - loss: 0.1610 - acc: 0.9645 - val_loss: 0.8386 - val_acc: 0.6181\n",
      "Epoch 8/100\n",
      "1295/1295 [==============================] - 1s 465us/step - loss: 0.1356 - acc: 0.9730 - val_loss: 1.0954 - val_acc: 0.5486\n",
      "Epoch 9/100\n",
      "1295/1295 [==============================] - 1s 428us/step - loss: 0.1142 - acc: 0.9822 - val_loss: 1.0964 - val_acc: 0.5486\n",
      "Epoch 10/100\n",
      "1295/1295 [==============================] - 1s 442us/step - loss: 0.1001 - acc: 0.9807 - val_loss: 1.0757 - val_acc: 0.5625\n",
      "Epoch 11/100\n",
      "1295/1295 [==============================] - 1s 433us/step - loss: 0.1034 - acc: 0.9853 - val_loss: 1.1948 - val_acc: 0.5000\n",
      "Epoch 12/100\n",
      "1295/1295 [==============================] - 1s 476us/step - loss: 0.0853 - acc: 0.9907 - val_loss: 1.1272 - val_acc: 0.5486\n",
      "Epoch 13/100\n",
      "1295/1295 [==============================] - 1s 442us/step - loss: 0.0762 - acc: 0.9946 - val_loss: 1.2244 - val_acc: 0.5069\n",
      "Epoch 14/100\n",
      "1295/1295 [==============================] - 1s 434us/step - loss: 0.0636 - acc: 0.9946 - val_loss: 1.1496 - val_acc: 0.5347\n",
      "Epoch 15/100\n",
      "1295/1295 [==============================] - 1s 431us/step - loss: 0.0621 - acc: 0.9900 - val_loss: 1.2119 - val_acc: 0.5347\n",
      "Epoch 16/100\n",
      "1295/1295 [==============================] - 1s 444us/step - loss: 0.0623 - acc: 0.9938 - val_loss: 1.1771 - val_acc: 0.5625\n",
      "Epoch 17/100\n",
      "1295/1295 [==============================] - 1s 516us/step - loss: 0.0576 - acc: 0.9954 - val_loss: 1.2378 - val_acc: 0.5278\n",
      "Epoch 18/100\n",
      "1295/1295 [==============================] - 1s 496us/step - loss: 0.0549 - acc: 0.9938 - val_loss: 1.2226 - val_acc: 0.5347\n",
      "Epoch 19/100\n",
      "1295/1295 [==============================] - 1s 497us/step - loss: 0.0540 - acc: 0.9954 - val_loss: 1.2138 - val_acc: 0.5556\n",
      "Epoch 20/100\n",
      "1295/1295 [==============================] - 1s 508us/step - loss: 0.0504 - acc: 0.9946 - val_loss: 1.2237 - val_acc: 0.5486\n",
      "Epoch 21/100\n",
      "1295/1295 [==============================] - 1s 478us/step - loss: 0.0408 - acc: 0.9985 - val_loss: 1.2662 - val_acc: 0.5486\n",
      "Epoch 22/100\n",
      "1295/1295 [==============================] - 1s 473us/step - loss: 0.0406 - acc: 0.9985 - val_loss: 1.2628 - val_acc: 0.5556\n",
      "Epoch 23/100\n",
      "1295/1295 [==============================] - 1s 447us/step - loss: 0.0343 - acc: 0.9992 - val_loss: 1.1764 - val_acc: 0.5833\n",
      "Epoch 24/100\n",
      "1295/1295 [==============================] - 1s 439us/step - loss: 0.0301 - acc: 1.0000 - val_loss: 1.2635 - val_acc: 0.5486\n",
      "Epoch 25/100\n",
      "1295/1295 [==============================] - 1s 440us/step - loss: 0.0281 - acc: 1.0000 - val_loss: 1.1935 - val_acc: 0.5625\n",
      "Epoch 26/100\n",
      "1295/1295 [==============================] - 1s 436us/step - loss: 0.0295 - acc: 0.9977 - val_loss: 1.3907 - val_acc: 0.5347\n",
      "Epoch 27/100\n",
      "1295/1295 [==============================] - 1s 494us/step - loss: 0.0370 - acc: 0.9946 - val_loss: 1.2568 - val_acc: 0.5625\n",
      "Epoch 28/100\n",
      "1295/1295 [==============================] - 1s 577us/step - loss: 0.0379 - acc: 0.9954 - val_loss: 1.3631 - val_acc: 0.5417\n",
      "Epoch 29/100\n",
      "1295/1295 [==============================] - 1s 481us/step - loss: 0.0337 - acc: 0.9969 - val_loss: 1.3909 - val_acc: 0.5278\n",
      "Epoch 30/100\n",
      "1295/1295 [==============================] - ETA: 0s - loss: 0.0260 - acc: 1.000 - 1s 516us/step - loss: 0.0265 - acc: 1.0000 - val_loss: 1.2090 - val_acc: 0.5625\n",
      "Epoch 31/100\n",
      "1295/1295 [==============================] - 1s 504us/step - loss: 0.0350 - acc: 0.9954 - val_loss: 1.0896 - val_acc: 0.6042\n",
      "Epoch 32/100\n",
      "1295/1295 [==============================] - 1s 458us/step - loss: 0.0260 - acc: 0.9985 - val_loss: 1.1844 - val_acc: 0.5903\n",
      "Epoch 33/100\n",
      "1295/1295 [==============================] - 1s 438us/step - loss: 0.0206 - acc: 1.0000 - val_loss: 1.1888 - val_acc: 0.5833\n",
      "Epoch 34/100\n",
      "1295/1295 [==============================] - 1s 465us/step - loss: 0.0218 - acc: 0.9992 - val_loss: 1.2144 - val_acc: 0.5694\n",
      "Epoch 35/100\n",
      "1295/1295 [==============================] - 1s 529us/step - loss: 0.0219 - acc: 0.9992 - val_loss: 1.2660 - val_acc: 0.5556\n",
      "Epoch 36/100\n",
      "1295/1295 [==============================] - 1s 562us/step - loss: 0.0211 - acc: 0.9992 - val_loss: 1.2839 - val_acc: 0.5694\n",
      "Epoch 37/100\n",
      "1295/1295 [==============================] - 1s 517us/step - loss: 0.0199 - acc: 1.0000 - val_loss: 1.2680 - val_acc: 0.5694\n",
      "Epoch 38/100\n",
      "1295/1295 [==============================] - 1s 460us/step - loss: 0.0190 - acc: 0.9992 - val_loss: 1.3456 - val_acc: 0.5486\n",
      "Epoch 39/100\n",
      "1295/1295 [==============================] - 1s 461us/step - loss: 0.0178 - acc: 1.0000 - val_loss: 1.2678 - val_acc: 0.5694\n",
      "Epoch 40/100\n",
      "1295/1295 [==============================] - 1s 449us/step - loss: 0.0186 - acc: 0.9992 - val_loss: 1.2060 - val_acc: 0.5833\n",
      "Epoch 41/100\n",
      "1295/1295 [==============================] - 1s 422us/step - loss: 0.0185 - acc: 0.9985 - val_loss: 1.3118 - val_acc: 0.5764\n",
      "Epoch 42/100\n",
      "1295/1295 [==============================] - 1s 459us/step - loss: 0.0180 - acc: 0.9992 - val_loss: 1.2529 - val_acc: 0.5625\n",
      "Epoch 43/100\n",
      "1295/1295 [==============================] - 1s 446us/step - loss: 0.0201 - acc: 1.0000 - val_loss: 1.1872 - val_acc: 0.5833\n",
      "Epoch 44/100\n",
      "1295/1295 [==============================] - 1s 451us/step - loss: 0.0189 - acc: 0.9985 - val_loss: 1.1810 - val_acc: 0.6319\n",
      "Epoch 45/100\n",
      "1295/1295 [==============================] - 1s 428us/step - loss: 0.0195 - acc: 0.9985 - val_loss: 1.3450 - val_acc: 0.5417\n",
      "Epoch 46/100\n",
      "1295/1295 [==============================] - 1s 439us/step - loss: 0.0191 - acc: 0.9992 - val_loss: 1.4019 - val_acc: 0.5486\n",
      "Epoch 47/100\n",
      "1295/1295 [==============================] - 1s 429us/step - loss: 0.0158 - acc: 1.0000 - val_loss: 1.3639 - val_acc: 0.5625\n",
      "Epoch 48/100\n",
      "1295/1295 [==============================] - 1s 430us/step - loss: 0.0151 - acc: 0.9985 - val_loss: 1.3417 - val_acc: 0.5486\n",
      "Epoch 49/100\n",
      "1295/1295 [==============================] - 1s 435us/step - loss: 0.0173 - acc: 0.9992 - val_loss: 1.2484 - val_acc: 0.5972\n",
      "Epoch 50/100\n",
      "1295/1295 [==============================] - 1s 443us/step - loss: 0.0160 - acc: 1.0000 - val_loss: 1.3128 - val_acc: 0.5694\n",
      "Epoch 51/100\n",
      "1295/1295 [==============================] - 1s 434us/step - loss: 0.0120 - acc: 1.0000 - val_loss: 1.3530 - val_acc: 0.5486\n",
      "Epoch 52/100\n",
      "1295/1295 [==============================] - 1s 441us/step - loss: 0.0158 - acc: 0.9985 - val_loss: 1.3557 - val_acc: 0.5417\n",
      "Epoch 53/100\n",
      "1295/1295 [==============================] - 1s 458us/step - loss: 0.0143 - acc: 1.0000 - val_loss: 1.3696 - val_acc: 0.5417\n",
      "Epoch 54/100\n",
      "1295/1295 [==============================] - 1s 439us/step - loss: 0.0136 - acc: 1.0000 - val_loss: 1.3487 - val_acc: 0.5486\n",
      "Epoch 55/100\n",
      "1295/1295 [==============================] - 1s 431us/step - loss: 0.0110 - acc: 0.9992 - val_loss: 1.3341 - val_acc: 0.5486\n",
      "Epoch 56/100\n",
      "1295/1295 [==============================] - 1s 458us/step - loss: 0.0123 - acc: 0.9992 - val_loss: 1.3498 - val_acc: 0.5486\n",
      "Epoch 57/100\n",
      "1295/1295 [==============================] - 1s 480us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.3456 - val_acc: 0.5625\n",
      "Epoch 58/100\n",
      "1295/1295 [==============================] - 1s 460us/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.3434 - val_acc: 0.5764\n",
      "Epoch 59/100\n",
      "1295/1295 [==============================] - 1s 442us/step - loss: 0.0129 - acc: 1.0000 - val_loss: 1.3522 - val_acc: 0.5694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "1295/1295 [==============================] - 1s 417us/step - loss: 0.0110 - acc: 0.9992 - val_loss: 1.3584 - val_acc: 0.5694\n",
      "Epoch 61/100\n",
      "1295/1295 [==============================] - 1s 417us/step - loss: 0.0105 - acc: 1.0000 - val_loss: 1.2391 - val_acc: 0.6111\n",
      "Epoch 62/100\n",
      "1295/1295 [==============================] - 1s 442us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.3512 - val_acc: 0.5764\n",
      "Epoch 63/100\n",
      "1295/1295 [==============================] - 1s 417us/step - loss: 0.0105 - acc: 0.9992 - val_loss: 1.4135 - val_acc: 0.5486\n",
      "Epoch 64/100\n",
      "1295/1295 [==============================] - 1s 417us/step - loss: 0.0116 - acc: 0.9992 - val_loss: 1.4330 - val_acc: 0.5625\n",
      "Epoch 65/100\n",
      "1295/1295 [==============================] - 1s 418us/step - loss: 0.0106 - acc: 0.9992 - val_loss: 1.3706 - val_acc: 0.5625\n",
      "Epoch 66/100\n",
      "1295/1295 [==============================] - 1s 440us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.5211 - val_acc: 0.5347\n",
      "Epoch 67/100\n",
      "1295/1295 [==============================] - 1s 446us/step - loss: 0.0091 - acc: 1.0000 - val_loss: 1.4935 - val_acc: 0.5417\n",
      "Epoch 68/100\n",
      "1295/1295 [==============================] - 1s 587us/step - loss: 0.0082 - acc: 0.9992 - val_loss: 1.4872 - val_acc: 0.5694\n",
      "Epoch 69/100\n",
      "1295/1295 [==============================] - 1s 444us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 1.5001 - val_acc: 0.5486\n",
      "Epoch 70/100\n",
      "1295/1295 [==============================] - 1s 426us/step - loss: 0.0081 - acc: 1.0000 - val_loss: 1.4770 - val_acc: 0.5625\n",
      "Epoch 71/100\n",
      "1295/1295 [==============================] - 1s 432us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 1.4112 - val_acc: 0.5694\n",
      "Epoch 72/100\n",
      "1295/1295 [==============================] - 1s 420us/step - loss: 0.0078 - acc: 0.9992 - val_loss: 1.4525 - val_acc: 0.5417\n",
      "Epoch 73/100\n",
      "1295/1295 [==============================] - 1s 435us/step - loss: 0.0102 - acc: 0.9992 - val_loss: 1.6330 - val_acc: 0.5417\n",
      "Epoch 74/100\n",
      "1295/1295 [==============================] - 1s 424us/step - loss: 0.0118 - acc: 0.9985 - val_loss: 1.4053 - val_acc: 0.5694\n",
      "Epoch 75/100\n",
      "1295/1295 [==============================] - 1s 423us/step - loss: 0.0114 - acc: 0.9985 - val_loss: 1.4035 - val_acc: 0.5625\n",
      "Epoch 76/100\n",
      "1295/1295 [==============================] - 1s 436us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 1.4250 - val_acc: 0.5556\n",
      "Epoch 77/100\n",
      "1295/1295 [==============================] - 1s 457us/step - loss: 0.0076 - acc: 1.0000 - val_loss: 1.4229 - val_acc: 0.5556\n",
      "Epoch 78/100\n",
      "1295/1295 [==============================] - 1s 429us/step - loss: 0.0086 - acc: 1.0000 - val_loss: 1.4459 - val_acc: 0.5556\n",
      "Epoch 79/100\n",
      "1295/1295 [==============================] - 1s 446us/step - loss: 0.0118 - acc: 0.9977 - val_loss: 1.5538 - val_acc: 0.5417\n",
      "Epoch 80/100\n",
      "1295/1295 [==============================] - 1s 436us/step - loss: 0.0098 - acc: 1.0000 - val_loss: 1.4548 - val_acc: 0.5486\n",
      "Epoch 81/100\n",
      "1295/1295 [==============================] - 1s 433us/step - loss: 0.0093 - acc: 1.0000 - val_loss: 1.4788 - val_acc: 0.5486\n",
      "Epoch 82/100\n",
      "1295/1295 [==============================] - ETA: 0s - loss: 0.0067 - acc: 1.000 - 1s 425us/step - loss: 0.0081 - acc: 0.9992 - val_loss: 1.4700 - val_acc: 0.5417\n",
      "Epoch 83/100\n",
      "1295/1295 [==============================] - 1s 433us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.4448 - val_acc: 0.5486\n",
      "Epoch 84/100\n",
      "1295/1295 [==============================] - 1s 424us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.4110 - val_acc: 0.5625\n",
      "Epoch 85/100\n",
      "1295/1295 [==============================] - 1s 441us/step - loss: 0.0075 - acc: 1.0000 - val_loss: 1.4360 - val_acc: 0.5556\n",
      "Epoch 86/100\n",
      "1295/1295 [==============================] - 1s 445us/step - loss: 0.0065 - acc: 1.0000 - val_loss: 1.3734 - val_acc: 0.5833\n",
      "Epoch 87/100\n",
      "1295/1295 [==============================] - 1s 426us/step - loss: 0.0076 - acc: 0.9992 - val_loss: 1.3144 - val_acc: 0.5972\n",
      "Epoch 88/100\n",
      "1295/1295 [==============================] - 1s 459us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.3608 - val_acc: 0.5972\n",
      "Epoch 89/100\n",
      "1295/1295 [==============================] - 1s 447us/step - loss: 0.0062 - acc: 1.0000 - val_loss: 1.3143 - val_acc: 0.5972\n",
      "Epoch 90/100\n",
      "1295/1295 [==============================] - 1s 486us/step - loss: 0.0066 - acc: 1.0000 - val_loss: 1.3601 - val_acc: 0.5972\n",
      "Epoch 91/100\n",
      "1295/1295 [==============================] - 1s 437us/step - loss: 0.0057 - acc: 1.0000 - val_loss: 1.3645 - val_acc: 0.5903\n",
      "Epoch 92/100\n",
      "1295/1295 [==============================] - 1s 468us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 1.3737 - val_acc: 0.5972\n",
      "Epoch 93/100\n",
      "1295/1295 [==============================] - 1s 466us/step - loss: 0.0084 - acc: 0.9992 - val_loss: 1.3964 - val_acc: 0.5972\n",
      "Epoch 94/100\n",
      "1295/1295 [==============================] - 1s 468us/step - loss: 0.0095 - acc: 0.9985 - val_loss: 1.4170 - val_acc: 0.5694\n",
      "Epoch 95/100\n",
      "1295/1295 [==============================] - 1s 441us/step - loss: 0.0066 - acc: 0.9992 - val_loss: 1.4687 - val_acc: 0.5833\n",
      "Epoch 96/100\n",
      "1295/1295 [==============================] - 1s 499us/step - loss: 0.0051 - acc: 1.0000 - val_loss: 1.4846 - val_acc: 0.5694\n",
      "Epoch 97/100\n",
      "1295/1295 [==============================] - 1s 451us/step - loss: 0.0074 - acc: 1.0000 - val_loss: 1.4547 - val_acc: 0.5764\n",
      "Epoch 98/100\n",
      "1295/1295 [==============================] - 1s 454us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 1.5263 - val_acc: 0.5694\n",
      "Epoch 99/100\n",
      "1295/1295 [==============================] - 1s 446us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 1.5273 - val_acc: 0.5694\n",
      "Epoch 100/100\n",
      "1295/1295 [==============================] - 1s 469us/step - loss: 0.0088 - acc: 0.9992 - val_loss: 1.4130 - val_acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14998e978>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model = Sequential()\n",
    "my_model.add(BatchNormalization(input_shape=train_X.shape[1:]))\n",
    "my_model.add(Dense(256, activation = \"relu\"))\n",
    "my_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "my_model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "my_model.fit(train_X, train_y,epochs=100,batch_size=30,validation_split=0.1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 images belonging to 4 classes.\n",
      "24/24 [==============================] - 156s 6s/step\n",
      "352/352 [==============================] - 0s 282us/step\n",
      "Accuracy score: 0.8522727272727273\n",
      "Log_loss score: 0.5200667234862363\n"
     ]
    }
   ],
   "source": [
    "test_generator=ImageDataGenerator(rescale=1. / 255).flow_from_directory(test_data_dir,\n",
    "target_size = (299, 299),\n",
    "batch_size = 15,\n",
    "class_mode = \"categorical\",\n",
    "shuffle=False)\n",
    "y_test=test_generator.classes\n",
    "test_generator.reset\n",
    "X_test=model.predict_generator(test_generator,verbose=1)\n",
    "y_pred=my_model.predict(X_test,verbose=1)\n",
    "accuracy=accuracy_score(y_test,y_pred.argmax(axis=1))\n",
    "log_loss=log_loss(y_test,y_pred)\n",
    "print (\"Accuracy score: {}\".format (accuracy))\n",
    "print (\"Log_loss score: {}\".format (log_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_model.save(\"inV3_last_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_dir=\"data/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 352 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator=ImageDataGenerator(rescale=1. / 255).flow_from_directory(test_data_dir,\n",
    "target_size = (299, 299),\n",
    "batch_size = 15, \n",
    "class_mode = \"categorical\",\n",
    "                                                     shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test=test_generator.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Iterator.reset of <keras.preprocessing.image.DirectoryIterator object at 0x1273da438>>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_generator.reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(input_shape=(299, 299, 3),\n",
    "                              weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 176s 7s/step\n"
     ]
    }
   ],
   "source": [
    "X_test=model.predict_generator(test_generator,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 3s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred=my_model.predict(X_test,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.9999452e-01, 1.1952590e-06, 3.4797871e-08, 4.2500669e-06],\n",
       "       [9.9999344e-01, 7.7219745e-08, 3.2914915e-07, 6.0775378e-06],\n",
       "       [4.9965445e-02, 2.2622485e-01, 5.1610544e-03, 7.1864861e-01],\n",
       "       ...,\n",
       "       [5.4245493e-03, 1.1264270e-03, 9.2897457e-01, 6.4474508e-02],\n",
       "       [4.8294063e-03, 2.3817454e-01, 7.5519055e-01, 1.8055416e-03],\n",
       "       [1.9877350e-06, 9.7551733e-01, 2.4129853e-02, 3.5086213e-04]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8522727272727273"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5200667234862363"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "my_model = Sequential()\n",
    "my_model.add(BatchNormalization(input_shape=train_X.shape[1:]))\n",
    "my_model.add(Dense(256, activation = \"relu\"))\n",
    "my_model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "my_model.compile(optimizer=sgd, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "#early = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')\n",
    "my_model.fit(train_X, train_y,epochs=200,batch_size=15,validation_split=0.1,verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
